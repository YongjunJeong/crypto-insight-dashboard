{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c0741a4-643f-4f53-9680-964a9e26e6d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks Notebook: Bronze ingest from Apyflux Binance Futures Leaderboard (positions)\n",
    "# Multi-account version (supports multiple encryptedUid → labeled as account_label)\n",
    "\n",
    "import json, time, datetime as dt, hashlib\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import requests\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, to_timestamp\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, DoubleType, LongType, BooleanType\n",
    ")\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# =========================\n",
    "# (A) 실행/프로젝트 설정\n",
    "# =========================\n",
    "MODE  = \"once\"          # once | poll | forever\n",
    "POLL_SECONDS = 60\n",
    "MAX_POLLS    = 120\n",
    "UPSERT_UPDATE_INGEST_TIME = True\n",
    "\n",
    "CATALOG = \"demo_catalog\"\n",
    "SCHEMA  = \"demo_schema\"\n",
    "TABLE   = f\"{CATALOG}.{SCHEMA}.bronze_futures_leaderboard_positions\"\n",
    "\n",
    "# 차트/캔들 조인 시 사용할 실버 테이블 명(필요 시 환경에 맞게 수정)\n",
    "SILVER_CHARTS = f\"{CATALOG}.{SCHEMA}.silver_charts\"\n",
    "\n",
    "BASE_URL       = \"https://gateway.apyflux.com\"\n",
    "PATH_POS       = \"/v1/getOtherPosition\"\n",
    "\n",
    "# ▶ 여러 계정(UID → 라벨): 대시보드 필터를 위해 라벨로도 저장\n",
    "ENCRYPTED_UIDS: Dict[str, str] = {\n",
    "    \"14EA12E7412DC5A21DFF5E7EAC6013B9\": \"ILLIT\",\n",
    "    \"38AF58C71A07AC6BDA18B8D97E7C3B00\": \"Geruntis\",\n",
    "    \"1A7A15511721C96C03D029D4BA0AA64F\": \"Anonymous_A\",\n",
    "    \"8E3794B912C699234158A15D3C9B9610\": \"Anonymous_B\",\n",
    "}\n",
    "\n",
    "# Databricks Secrets\n",
    "HEADERS = {\n",
    "    \"x-app-id\":    dbutils.secrets.get(\"apyflux\", \"x_app_id\"),\n",
    "    \"x-client-id\": dbutils.secrets.get(\"apyflux\", \"x_client_id\"),\n",
    "    \"x-api-key\":   dbutils.secrets.get(\"apyflux\", \"x_api_key\"),\n",
    "    \"Content-Type\":\"application/json\",\n",
    "}\n",
    "\n",
    "# 스키마 자동 병합: 새 컬럼 추가 시 안전\n",
    "spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\", \"true\")\n",
    "\n",
    "# =========================\n",
    "# (B) 테이블 준비\n",
    "# =========================\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG}\")\n",
    "spark.sql(f\"CREATE SCHEMA  IF NOT EXISTS {CATALOG}.{SCHEMA}\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {TABLE} (\n",
    "  source            STRING,     -- \"apyflux.binance.futures.leaderboard\"\n",
    "  endpoint_name     STRING,     -- \"getOtherPosition\"\n",
    "  uid               STRING,     -- encryptedUid\n",
    "  account_label     STRING,     -- 계정 식별/필터용 라벨\n",
    "  symbol            STRING,     -- 포지션 심볼\n",
    "  entryPrice        DOUBLE,\n",
    "  markPrice         DOUBLE,\n",
    "  pnl               DOUBLE,\n",
    "  roe               DOUBLE,\n",
    "  amount            DOUBLE,\n",
    "  leverage          DOUBLE,\n",
    "  yellow            BOOLEAN,\n",
    "  tradeBefore       BOOLEAN,\n",
    "  update_ts         LONG,       -- 이벤트 시각(ms)\n",
    "  event_time        TIMESTAMP,  -- update_ts 기반\n",
    "  ingest_time       TIMESTAMP,  -- 적재 시각\n",
    "  unique_key        STRING,\n",
    "  raw_json          STRING,     -- 원본 JSON\n",
    "  api_endpoint      STRING,     -- 호출 경로\n",
    "  api_params_hash   STRING,     -- 요청 파라미터 해시\n",
    "  dt                DATE\n",
    ") USING DELTA\n",
    "PARTITIONED BY (dt)\n",
    "\"\"\")\n",
    "\n",
    "# =========================\n",
    "# (C) 유틸리티\n",
    "# =========================\n",
    "def params_hash(params: Dict) -> str:\n",
    "    payload = json.dumps(params, sort_keys=True, separators=(\",\", \":\"))\n",
    "    return hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def _to_ms(d: dt.datetime) -> int:\n",
    "    if d.tzinfo is None:\n",
    "        d = d.replace(tzinfo=dt.timezone.utc)\n",
    "    return int(d.timestamp() * 1000)\n",
    "\n",
    "def _parse_update_ms(item: Dict, now_ms: int) -> int:\n",
    "    \"\"\"\n",
    "    updateTimeStamp(ms) 또는 updateTime([Y,M,D,h,m,s,ns])를 ms로 변환.\n",
    "    둘 다 없으면 now_ms.\n",
    "    \"\"\"\n",
    "    uts = item.get(\"updateTimeStamp\")\n",
    "    if isinstance(uts, (int, float, str)):\n",
    "        try:\n",
    "            return int(uts)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    ut = item.get(\"updateTime\")\n",
    "    if isinstance(ut, list) and len(ut) >= 6:\n",
    "        Y, M, D, h, m, s = [int(x) for x in ut[:6]]\n",
    "        ns = int(ut[6]) if len(ut) >= 7 else 0\n",
    "        ms_part = ns / 1_000_000\n",
    "        dt_utc = dt.datetime(Y, M, D, h, m, s, int(ms_part * 1000), tzinfo=dt.timezone.utc)\n",
    "        return _to_ms(dt_utc)\n",
    "\n",
    "    return now_ms\n",
    "\n",
    "def _fetch_positions(enc_uid: str) -> Tuple[List[Dict], Dict[str,str], Dict[str,str], str]:\n",
    "    \"\"\"Apyflux getOtherPosition → (rows, headers, params, endpoint_path)\"\"\"\n",
    "    url    = f\"{BASE_URL}{PATH_POS}\"\n",
    "    params = {\"encryptedUid\": enc_uid}\n",
    "    r = requests.get(url, headers=HEADERS, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    payload = r.json()\n",
    "    data = payload.get(\"data\", {}) if isinstance(payload, dict) else {}\n",
    "    rows = data.get(\"otherPositionRetList\", []) or []\n",
    "    return rows, dict(r.headers), params, PATH_POS\n",
    "\n",
    "def _rows_to_bronze(enc_uid: str, account_label: str, rows: List[Dict], endpoint: str, params: Dict) -> int:\n",
    "    \"\"\"positions rows(list[dict]) → Bronze Delta UPSERT(idempotent) for one account\"\"\"\n",
    "    if not rows:\n",
    "        print(f\"[INFO] no rows returned for uid={enc_uid}\")\n",
    "        return 0\n",
    "\n",
    "    now = dt.datetime.now(dt.timezone.utc)\n",
    "    now_iso = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    now_ms  = _to_ms(now)\n",
    "    p_hash  = params_hash(params)\n",
    "\n",
    "    recs = []\n",
    "    for item in rows:\n",
    "        sym    = item.get(\"symbol\")\n",
    "        upd_ms = _parse_update_ms(item, now_ms)\n",
    "        ev     = dt.datetime.fromtimestamp(upd_ms/1000, tz=dt.timezone.utc)\n",
    "\n",
    "        recs.append({\n",
    "            \"source\":          \"apyflux.binance.futures.leaderboard\",\n",
    "            \"endpoint_name\":   \"getOtherPosition\",\n",
    "            \"uid\":             enc_uid,\n",
    "            \"account_label\":   account_label,\n",
    "            \"symbol\":          sym,\n",
    "            \"entryPrice\":      float(item[\"entryPrice\"]) if item.get(\"entryPrice\") is not None else None,\n",
    "            \"markPrice\":       float(item[\"markPrice\"])  if item.get(\"markPrice\")  is not None else None,\n",
    "            \"pnl\":             float(item[\"pnl\"])        if item.get(\"pnl\")        is not None else None,\n",
    "            \"roe\":             float(item[\"roe\"])        if item.get(\"roe\")        is not None else None,\n",
    "            \"amount\":          float(item[\"amount\"])     if item.get(\"amount\")     is not None else None,\n",
    "            \"leverage\":        float(item[\"leverage\"])   if item.get(\"leverage\")   is not None else None,\n",
    "            \"yellow\":          bool(item[\"yellow\"])      if item.get(\"yellow\")     is not None else None,\n",
    "            \"tradeBefore\":     bool(item[\"tradeBefore\"]) if item.get(\"tradeBefore\")is not None else None,\n",
    "            \"update_ts\":       int(upd_ms),\n",
    "            \"event_time\":      ev.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"ingest_time\":     now_iso,\n",
    "            \"unique_key\":      f\"pos|{enc_uid}|{sym}|{upd_ms}\",\n",
    "            \"raw_json\":        json.dumps(item, separators=(\",\", \":\")),\n",
    "            \"api_endpoint\":    endpoint,\n",
    "            \"api_params_hash\": p_hash,\n",
    "            \"dt\":              ev.date().isoformat(),\n",
    "        })\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField(\"source\",          StringType(), True),\n",
    "        StructField(\"endpoint_name\",   StringType(), True),\n",
    "        StructField(\"uid\",             StringType(), True),\n",
    "        StructField(\"account_label\",   StringType(), True),\n",
    "        StructField(\"symbol\",          StringType(), True),\n",
    "        StructField(\"entryPrice\",      DoubleType(), True),\n",
    "        StructField(\"markPrice\",       DoubleType(), True),\n",
    "        StructField(\"pnl\",             DoubleType(), True),\n",
    "        StructField(\"roe\",             DoubleType(), True),\n",
    "        StructField(\"amount\",          DoubleType(), True),\n",
    "        StructField(\"leverage\",        DoubleType(), True),\n",
    "        StructField(\"yellow\",          BooleanType(), True),\n",
    "        StructField(\"tradeBefore\",     BooleanType(), True),\n",
    "        StructField(\"update_ts\",       LongType(),   True),\n",
    "        StructField(\"event_time\",      StringType(), True),\n",
    "        StructField(\"ingest_time\",     StringType(), True),\n",
    "        StructField(\"unique_key\",      StringType(), True),\n",
    "        StructField(\"raw_json\",        StringType(), True),\n",
    "        StructField(\"api_endpoint\",    StringType(), True),\n",
    "        StructField(\"api_params_hash\", StringType(), True),\n",
    "        StructField(\"dt\",              StringType(), True),\n",
    "    ])\n",
    "\n",
    "    df = (spark.createDataFrame([Row(**r) for r in recs], schema)\n",
    "            .withColumn(\"event_time\",  to_timestamp(col(\"event_time\")))\n",
    "            .withColumn(\"ingest_time\", to_timestamp(col(\"ingest_time\")))\n",
    "            .withColumn(\"dt\",          col(\"dt\").cast(\"date\"))\n",
    "            .dropDuplicates([\"unique_key\"])\n",
    "         )\n",
    "\n",
    "    delta_table = DeltaTable.forName(spark, TABLE)\n",
    "    set_map = {\n",
    "        \"source\":          \"s.source\",\n",
    "        \"endpoint_name\":   \"s.endpoint_name\",\n",
    "        \"uid\":             \"s.uid\",\n",
    "        \"account_label\":   \"s.account_label\",\n",
    "        \"symbol\":          \"s.symbol\",\n",
    "        \"entryPrice\":      \"s.entryPrice\",\n",
    "        \"markPrice\":       \"s.markPrice\",\n",
    "        \"pnl\":             \"s.pnl\",\n",
    "        \"roe\":             \"s.roe\",\n",
    "        \"amount\":          \"s.amount\",\n",
    "        \"leverage\":        \"s.leverage\",\n",
    "        \"yellow\":          \"s.yellow\",\n",
    "        \"tradeBefore\":     \"s.tradeBefore\",\n",
    "        \"update_ts\":       \"s.update_ts\",\n",
    "        \"event_time\":      \"s.event_time\",\n",
    "        \"raw_json\":        \"s.raw_json\",\n",
    "        \"api_endpoint\":    \"s.api_endpoint\",\n",
    "        \"api_params_hash\": \"s.api_params_hash\",\n",
    "        \"dt\":              \"s.dt\",\n",
    "    }\n",
    "    set_map[\"ingest_time\"] = \"s.ingest_time\" if UPSERT_UPDATE_INGEST_TIME else \"t.ingest_time\"\n",
    "\n",
    "    (delta_table.alias(\"t\")\n",
    "        .merge(df.alias(\"s\"), \"t.unique_key = s.unique_key AND t.dt = s.dt\")\n",
    "        .whenMatchedUpdate(set=set_map)\n",
    "        .whenNotMatchedInsertAll()\n",
    "        .execute())\n",
    "\n",
    "    return df.count()\n",
    "\n",
    "def ingest_for_account(enc_uid: str, label: str) -> int:\n",
    "    rows, headers, params, ep = _fetch_positions(enc_uid)\n",
    "    cnt = _rows_to_bronze(enc_uid, label, rows, ep, params)\n",
    "    rem = headers.get(\"X-RateLimit-Remaining\") or headers.get(\"x-ratelimit-remaining\")\n",
    "    if rem is not None:\n",
    "        print(f\"[Apyflux] remaining: {rem} (uid={enc_uid})\")\n",
    "    print(f\"[Bronze LB] +{cnt} rows (uid={enc_uid}, label={label})\")\n",
    "    return cnt\n",
    "\n",
    "def ingest_many(uid_map: Dict[str, str]) -> int:\n",
    "    total = 0\n",
    "    for uid, label in uid_map.items():\n",
    "        try:\n",
    "            total += ingest_for_account(uid, label)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] uid={uid} ({label}) failed: {e}\")\n",
    "            time.sleep(2)\n",
    "    return total\n",
    "\n",
    "# =========================\n",
    "# (D) MAIN\n",
    "# =========================\n",
    "if MODE == \"once\":\n",
    "    ingest_many(ENCRYPTED_UIDS)\n",
    "    dbutils.notebook.exit(\"leaderboard positions once done\")\n",
    "\n",
    "elif MODE == \"poll\":\n",
    "    for _ in range(MAX_POLLS):\n",
    "        ingest_many(ENCRYPTED_UIDS)\n",
    "        time.sleep(POLL_SECONDS)\n",
    "    dbutils.notebook.exit(\"leaderboard positions poll done\")\n",
    "\n",
    "else:  # forever\n",
    "    print(f\"[LIVE] polling every {POLL_SECONDS}s for {len(ENCRYPTED_UIDS)} accounts\")\n",
    "    while True:\n",
    "        try:\n",
    "            ingest_many(ENCRYPTED_UIDS)\n",
    "        except Exception as exc:\n",
    "            print(f\"[WARN] {exc}\")\n",
    "            time.sleep(5)\n",
    "        time.sleep(POLL_SECONDS)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7965387922038003,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01c_ingest_bronze_leaderboard_apyflux.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
