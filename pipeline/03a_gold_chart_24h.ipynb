{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25375171-727d-40d2-9c82-040f7b6805d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks Notebook: Silver -> Gold (15m series for chart & 24h change)\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# ========== 설정 ==========\n",
    "CATALOG = \"demo_catalog\"\n",
    "SCHEMA  = \"demo_schema\"\n",
    "SILVER  = f\"{CATALOG}.{SCHEMA}.silver_charts\"      # 15m 캔들 원본(Silver)\n",
    "GOLD_15 = f\"{CATALOG}.{SCHEMA}.gold_prices_15m\"    # 차트/24h%용 Gold\n",
    "DAYS_BACK = 10                                      # 최근 N일만 재계산(7일 차트 + 여유)\n",
    "\n",
    "# ========== 타깃 테이블 생성(없으면) ==========\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {GOLD_15} (\n",
    "  symbol        STRING,\n",
    "  interval      STRING,\n",
    "  open_time     TIMESTAMP,\n",
    "  close         DOUBLE,\n",
    "  ma50_15m      DOUBLE,\n",
    "  ma200_15m     DOUBLE,\n",
    "  pct_change_24h DOUBLE,\n",
    "  dt            DATE\n",
    ") USING DELTA\n",
    "PARTITIONED BY (dt)\n",
    "\"\"\")\n",
    "\n",
    "# ========== 소스 로드(증분 범위) ==========\n",
    "src = (\n",
    "  spark.table(SILVER)\n",
    "       .where(\"open_time IS NOT NULL\")\n",
    "       .where(\"interval = '15m'\")\n",
    "       .where(f\"dt >= date_sub(current_date(), {DAYS_BACK})\")\n",
    "       .select(\"symbol\",\"interval\",\"open_time\",\"close\",\"dt\")\n",
    ")\n",
    "\n",
    "# 15m 이동평균 창(행 단위: 50/200개)\n",
    "w_sym = Window.partitionBy(\"symbol\").orderBy(F.col(\"open_time\"))\n",
    "w50    = w_sym.rowsBetween(-49, 0)\n",
    "w200   = w_sym.rowsBetween(-199, 0)\n",
    "\n",
    "# 24h 변화%: 15분 봉 96개 = 24시간\n",
    "w96    = w_sym.rowsBetween(-96, -96)\n",
    "\n",
    "gold_15_df = (\n",
    "  src\n",
    "    .withColumn(\"ma50_15m\",   F.avg(\"close\").over(w50))\n",
    "    .withColumn(\"ma200_15m\",  F.avg(\"close\").over(w200))\n",
    "    .withColumn(\"close_24h_ago\", F.last(\"close\").over(w96))\n",
    "    .withColumn(\n",
    "        \"pct_change_24h\",\n",
    "        F.when(F.col(\"close_24h_ago\").isNull(), F.lit(None).cast(\"double\"))\n",
    "         .otherwise((F.col(\"close\") - F.col(\"close_24h_ago\")) / F.col(\"close_24h_ago\") * 100.0)\n",
    "    )\n",
    "    .select(\"symbol\",\"interval\",\"open_time\",\"close\",\"ma50_15m\",\"ma200_15m\",\"pct_change_24h\",\"dt\")\n",
    ")\n",
    "\n",
    "# 증분 구간만 MERGE (키: symbol, open_time)\n",
    "gold_15_df.createOrReplaceTempView(\"gold15_upserts\")\n",
    "spark.sql(f\"\"\"\n",
    "MERGE INTO {GOLD_15} AS t\n",
    "USING gold15_upserts AS s\n",
    "ON  t.symbol = s.symbol AND t.open_time = s.open_time\n",
    "WHEN MATCHED THEN UPDATE SET\n",
    "  t.interval       = s.interval,\n",
    "  t.close          = s.close,\n",
    "  t.ma50_15m       = s.ma50_15m,\n",
    "  t.ma200_15m      = s.ma200_15m,\n",
    "  t.pct_change_24h = s.pct_change_24h,\n",
    "  t.dt             = s.dt\n",
    "WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\")\n",
    "\n",
    "print(f\"[GOLD_15] upsert complete: {GOLD_15}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03a_gold_chart_24h",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
